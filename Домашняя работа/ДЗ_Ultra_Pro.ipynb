{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Задание"
      ],
      "metadata": {
        "id": "ujUTHlu4BKay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Распознайте рукописную цифру, написанную на листе от руки.\n",
        "Последовательность шагов следующая:\n",
        "\n",
        "*   На бумаге рисуем произвольную цифру (желательно нарисовать цифру размером не\n",
        "более 5 * 5 мм и без наклона. В занятии нейронка обучалась на цифрах американских студентов. Эти цифры были написаны на тетрадных листах в клетку и имели схожий размер).\n",
        "*   Фотографируем. Загружаем фото в Collaboratory.\n",
        "*   С помощью функции image.load_img(path, target_size=(28, 28), color_mode = ‘grayscale’) загружаем картинку в переменную.\n",
        "*   С помощью функции image.img_to_array(img) преобразуем изображение в numpy-массив.\n",
        "*   Выполняем инверсию цветов, нормирование и решейп массива.\n",
        "*   Выполняем распознавание собственной рукописной цифры.\n",
        "\n",
        "Примечание: точность распознавания рукописных цифр может быть достаточно низкой, т.к. рукописные цифры после преобразований хоть и похожи на содержащиеся в базе, но могут отличаться по конфигурации, толщине линий и т.д."
      ],
      "metadata": {
        "id": "vKgnksZcEAdw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Импорт необходимых библиотек для работы с распознаванием цифр\n",
        "В этом блоке подключаются модули, необходимые для загрузки обучающего датасета и создания нейронной сети:\n",
        "\n",
        "- from tensorflow.keras.datasets import mnist — загрузка встроенного набора данных MNIST с изображениями рукописных цифр (28×28 пикселей).\n",
        "\n",
        "- from tensorflow.keras import utils — утилиты Keras, включая to_categorical для one-hot кодирования меток.\n",
        "\n",
        "- from tensorflow.keras.models import Sequential — используется для создания модели нейронной сети типа \"последовательная\".\n",
        "\n",
        "- from tensorflow.keras.layers import Dense — импорт слоя плотных (полносвязных) нейронов.\n",
        "\n",
        "- import numpy as np — работа с массивами и матрицами (NumPy — основной инструмент для обработки числовых данных)."
      ],
      "metadata": {
        "id": "eGs7HS38B7dP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np                           # Работа с массивами\n",
        "import os                                   # Работа с файловой системой\n",
        "import warnings                             # Подавление предупреждений\n",
        "from tensorflow.keras import utils          # Утилиты Keras (to_categorical и др.)\n",
        "from tensorflow.keras.datasets import mnist # Загрузка датасета MNIST\n",
        "from tensorflow.keras.layers import Dense   # Полносвязный слой\n",
        "from tensorflow.keras.models import Sequential  # Создание нейросети\n",
        "\n",
        "# Отключаем предупреждения, чтобы не мешали выводу\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "FLWztPNsEXur"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Подготовка данных из набора MNIST\n",
        "В этом блоке производится загрузка и предварительная обработка изображений рукописных цифр из набора MNIST:\n",
        "\n",
        "Происходи загрузка данных:\n",
        "- mnist.load_data() загружает обучающую и тестовую выборки, содержащие изображения (размером 28×28 пикселей) и соответствующие им метки.\n",
        "\n",
        "Изменение формы входных данных:\n",
        "- Изображения преобразуются в векторы длиной 784 (28×28) с помощью reshape, чтобы передать их в полносвязную нейронную сеть.\n",
        "\n",
        "Нормализация:\n",
        "- Все пиксели приводятся к диапазону [0, 1], делением на 255, и тип данных меняется на float32.\n",
        "\n",
        "Преобразование меток:\n",
        "- Метки классов (y_train и y_test) переводятся в формат one-hot encoding, где каждая цифра представляется как вектор из 10 элементов (по числу классов от 0 до 9)."
      ],
      "metadata": {
        "id": "r1jOESuUCviA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train_org, y_train_org), (x_test_org, y_test_org) = mnist.load_data()\n",
        "\n",
        "x_train = x_train_org.reshape(x_train_org.shape[0], -1)\n",
        "x_test = x_test_org.reshape(x_test_org.shape[0], -1)\n",
        "\n",
        "# Преобразование x_train в тип float32 (числа с плавающей точкой) и нормализация\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "\n",
        "# Преобразование x_test в тип float32 (числа с плавающей точкой) и нормализация\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "CLASS_COUNT = 10\n",
        "\n",
        "\n",
        "# Преобразование ответов в формат one_hot_encoding\n",
        "y_train = utils.to_categorical(y_train_org, CLASS_COUNT)\n",
        "y_test = utils.to_categorical(y_test_org, CLASS_COUNT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vb_-JelpEa5k",
        "outputId": "4fe6c7ad-e1ee-4225-c8d4-3611d3399149"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Создание и компиляция нейронной сети для распознавания цифр\n",
        "В этом блоке формируется архитектура нейронной сети и её подготовка к обучению:\n",
        "\n",
        "Выполняется моздание модели, используется последовательная модель Sequential, где слои добавляются один за другим.\n",
        "\n",
        "Полносвязные слои:\n",
        "\n",
        "- Первый скрытый слой содержит 800 нейронов с активацией ReLU и принимает на вход векторы длиной 784 (28×28 пикселей, развернутые в вектор).\n",
        "\n",
        "- Второй скрытый слой — 400 нейронов с активацией ReLU, что помогает модели учиться сложным представлениям.\n",
        "\n",
        "Выходной слой:\n",
        "- Состоит из 10 нейронов (по числу классов от 0 до 9), использует функцию активации softmax для получения вероятностей классов.\n",
        "\n",
        "Далее выполняется компиляция:\n",
        "- Используется функция потерь categorical_crossentropy (подходит для многоклассовой классификации), оптимизатор Adam и метрика точности (accuracy)."
      ],
      "metadata": {
        "id": "to-XIIZ2DNMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание последовательной модели\n",
        "model = Sequential()\n",
        "\n",
        "# Добавление полносвязного слоя на 800 нейронов с relu-активацией\n",
        "model.add(Dense(800, input_dim=784, activation=\"relu\"))\n",
        "\n",
        "# Добавление полносвязного слоя на 400 нейронов с relu-активацией\n",
        "model.add(Dense(400, activation=\"relu\"))\n",
        "\n",
        "# Добавление полносвязного слоя с количеством нейронов по числу классов с softmax-активацией\n",
        "model.add(Dense(CLASS_COUNT, activation=\"softmax\"))\n",
        "\n",
        "# Компиляция модели\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "5iorRVdEEa6P"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Обучение нейронной сети\n",
        "В данном блоке происходит процесс обучения модели на подготовленных данных:\n",
        "\n",
        "Входные данные:\n",
        "- Используются нормализованные векторы изображений x_train и соответствующие one-hot метки y_train.\n",
        "\n",
        "Параметры обучения:\n",
        "\n",
        "- batch_size=128 — сеть обновляет веса после обработки каждого батча из 128 примеров.\n",
        "\n",
        "- epochs=15 — модель проходит 15 полных циклов по всему набору данных.\n",
        "\n",
        "- verbose=1 — вывод подробной информации о ходе обучения в консоль.\n"
      ],
      "metadata": {
        "id": "t2gjT10mDpDf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    x_train,  # обучающая выборка, входные данные\n",
        "    y_train,  # обучающая выборка, выходные данные\n",
        "    batch_size=128,  # кол-во примеров, которое обрабатывает нейронка перед одним изменением весов\n",
        "    epochs=15,  # количество эпох, когда нейронка обучается на всех примерах выборки\n",
        "    verbose=1,\n",
        ")  # 0 - не визуализировать ход обучения, 1 - визуализировать"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvWyVBF9El_j",
        "outputId": "ad323d63-f002-4cf8-a556-d7a2a7c1065e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8892 - loss: 0.3750\n",
            "Epoch 2/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9745 - loss: 0.0811\n",
            "Epoch 3/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9846 - loss: 0.0474\n",
            "Epoch 4/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9892 - loss: 0.0324\n",
            "Epoch 5/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9922 - loss: 0.0236\n",
            "Epoch 6/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9930 - loss: 0.0211\n",
            "Epoch 7/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9945 - loss: 0.0166\n",
            "Epoch 8/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9957 - loss: 0.0136\n",
            "Epoch 9/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9967 - loss: 0.0102\n",
            "Epoch 10/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9961 - loss: 0.0120\n",
            "Epoch 11/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9961 - loss: 0.0123\n",
            "Epoch 12/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0090\n",
            "Epoch 13/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9972 - loss: 0.0087\n",
            "Epoch 14/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9966 - loss: 0.0104\n",
            "Epoch 15/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0066\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79ae323db110>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Далее были реализованы операции по сохранению и восстановлению обученных параметров нейронной сети:\n",
        "\n",
        "Сохранение весов:\n",
        "- model.save_weights(\"dz_ultra_pro.weights.h5\") — сохраняет текущие веса модели в файл с расширением .h5. Это удобно для последующего использования без необходимости повторного обучения.\n",
        "\n",
        "Загрузка весов:\n",
        "- model.load_weights(\"dz_ultra_pro.weights.h5\") — загружает сохранённые веса из файла, позволяя восстановить состояние модели и сразу использовать её для предсказаний или дальнейшего обучения."
      ],
      "metadata": {
        "id": "c7s8BvafD4UO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights(\"dz_ultra_pro.weights.h5\")\n",
        "model.load_weights(\"dz_ultra_pro.weights.h5\")"
      ],
      "metadata": {
        "id": "Odx1EHJ-E3NJ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Далее подключаются необходимые инструменты для работы с изображениями и подключения к Google Диску:\n",
        "\n",
        "- from tensorflow.keras.preprocessing import image — загрузка и предобработка изображений.\n",
        "\n",
        "- import matplotlib.pyplot as plt — библиотека для визуализации изображений и графиков.\n",
        "\n",
        "- from google.colab import drive и drive.mount('/content/drive') — монтирование Google Диска для загрузки и сохранения файлов в среде Google Colaboratory."
      ],
      "metadata": {
        "id": "ts8GAM3JEHXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "zTGuxsIzE6K7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d3a8c42-178d-40db-8812-20d2aa84ee0b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Загрузка, предобработка и визуализация пользовательского изображения\n",
        "В этом блоке происходит подготовка рукописной цифры, загруженной с Google Диска, для распознавания:\n",
        "\n",
        "- image.load_img() загружает фото по пути img_path, масштабируя его до размера 28×28 пикселей и переводя в оттенки серого.\n",
        "\n",
        "- Преобразование в массив: image.img_to_array() конвертирует изображение в числовой массив.\n",
        "\n",
        "- Инверсия цветов: для правильного распознавания цвета цифры и фона цвета инвертируются: белый становится чёрным и наоборот (255 - img_array).\n",
        "\n",
        "- Пороговая фильтрация: пиксели с интенсивностью ниже 150 устанавливаются в 0 — это помогает убрать шумы и выделить фигуру.\n",
        "\n",
        "- Визуализация: отображение обработанного изображения с помощью plt.imshow() в оттенках серого.\n",
        "\n",
        "- Подготовка к модели: массив преобразуется в вектор, нормируется (деление на 255) и приводится к типу float32 для подачи в нейронную сеть."
      ],
      "metadata": {
        "id": "hpnG721VEXrV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = \"/content/drive/My Drive/Evdakov_1_Laba/image1.jpg\"\n",
        "img = image.load_img(img_path, target_size=(28, 28), color_mode='grayscale')\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = 255 - img_array\n",
        "img_array = np.where(img_array < 150, 0, img_array)\n",
        "plt.imshow(img_array, cmap=\"gray\")\n",
        "img_train = img_array.reshape(1, -1).astype(\"float32\")  / 255.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "bJse3V6bE6Lh",
        "outputId": "107d8423-ac02-426c-a70f-2c4ff67b6be6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Предсказание класса рукописной цифры.\n",
        "\n",
        "Прогнозирование: model.predict(img_train) вычисляет вероятности для каждого из 10 классов (цифр от 0 до 9).\n",
        "\n",
        "Определение класса: np.argmax(prediction) выбирает класс с максимальной вероятностью — это и есть распознанная цифра."
      ],
      "metadata": {
        "id": "WxGIODISEyM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model.predict(img_train)\n",
        "predicted_class = np.argmax(prediction)\n",
        "print(\"Распознанная цифра:\", predicted_class)"
      ],
      "metadata": {
        "id": "_sTXbjdEFDWJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "864e4a09-7aa3-4867-99e7-a71dc279a283"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step\n",
            "Распознанная цифра: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Вывод по заданию\n",
        "В данном задании была создана и обучена глубокая нейронная сеть для распознавания рукописных цифр из набора MNIST. Модель успешно справилась с задачей классификации, достигнув высокой точности благодаря использованию нескольких полносвязных слоев с функцией активации ReLU и softmax на выходе. Кроме того, была реализована обработка пользовательского изображения: оно было загружено, приведено к нужному формату, инвертировано и нормализовано для корректного распознавания. Итоговое предсказание продемонстрировало, что сеть способна распознавать собственноручно написанные цифры, хотя качество распознавания может зависеть от особенностей изображения — размера, толщины линий и контраста."
      ],
      "metadata": {
        "id": "3f4KoFTYE2DB"
      }
    }
  ]
}